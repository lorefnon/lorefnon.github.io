{
    "version": "https://jsonfeed.org/version/1",
    "title": "Icicles of Thought â€¢ All posts by \"jq\" tag",
    "description": "",
    "home_page_url": "https://lorefnon.me",
    "items": [
        {
            "id": "https://lorefnon.me/2020/11/27/exploring-har-http-archive-logs-with-jq/",
            "url": "https://lorefnon.me/2020/11/27/exploring-har-http-archive-logs-with-jq/",
            "title": "Exporing HAR (HTTP Archive) logs with Jq",
            "date_published": "2020-11-27T00:00:00.000Z",
            "content_html": "<p><a href=\"https://stedolan.github.io/jq/\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">Jq</a> is a versatile utility for quickly exploring/filtering/transforming JSON on the command line. It is similar to grep/sed/awk utilities in that it is standalone, portable and composable. If you are not familiar with basics of jq yet, I recommend skimming through the well written <a href=\"https://stedolan.github.io/jq/manual\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">official manual</a>.</p>\n<p>The HTTP Archive format, or HAR, is a JSON-formatted archive file format for logging of a web browser&#39;s interaction with a site (Source: <a href=\"https://en.wikipedia.org/wiki/HAR_(file_format)\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">Wikipedia</a>. Both Chrome and Firefox provide a <a href=\"https://knowledge.vidyard.com/hc/en-us/articles/360009996213-Download-a-HAR-file-from-your-browser\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">convenient option</a> to download information about all the http requests when visiting a particular site as a HAR file which makes it a very useful format in practice.</p>\n<p>One simple way to analyze HAR files is to import them back into dev-tools and explore them manually. But for many common scenarios it is more efficient to analyze these files through CLI using a tool like jq to zero into the exact information we need.</p>\n<p>The rest of this post is basically a cheatsheet of one-liners for using jq to analyze HAR logs. It mostly covers scenarios that I have found useful in day-to-day exploration as a web developer.</p>\n<p>For the examples here I&#39;ll be using the HAR exported from twitter.com (I am <a href=\"https://twitter.com/lorefnon\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">@lorefnon</a> on twitter as well BTW).</p>\n<p>You may or may not have familiar with the structure of HAR file. Let&#39;s see how we can explore some JSON of unfamiliar structure.</p>\n<p>For starters, jq can be used a simple JSON formatter or syntax highligher.</p>\n<p>So something like this gives us properly formatted syntax highlighted json:</p>\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;.&#x27;</span> twitter.com.har</code></pre>\n\n<p>Or we can feed in json through STDIN which is quite useful with curl etc.:</p>\n<pre><code class=\"hljs sh\">$ cat twitter.com.har | jq <span class=\"hljs-string\">&#x27;.&#x27;</span></code></pre>\n\n<p>This essentially applies an identity filter (<code>.</code>) to input (incoming stream) that returns it unchanged, and lets jq pretty-prints the output.</p>\n<p>However, HAR files are often fairly large, and thus this is unweildy when you have several MBs of content.</p>\n<p>So let us just find out the top level keys to begin with:</p>\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;. | keys&#x27;</span> twitter.com.har\n\n[\n  <span class=\"hljs-string\">&quot;log&quot;</span>\n]</code></pre>\n\n<p>Pipe (|) similar to unix pipes is jq&#39;s syntax for forward application. In this case the output of identity filter to the <code>keys</code> builtin function which returns us an array of keys in the object.</p>\n<p>And now we can drill down from there and explore the subtree:</p>\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;.log | keys&#x27;</span> twitter.com.har\n\n[\n  <span class=\"hljs-string\">&quot;creator&quot;</span>,\n  <span class=\"hljs-string\">&quot;entries&quot;</span>,\n  <span class=\"hljs-string\">&quot;pages&quot;</span>,\n  <span class=\"hljs-string\">&quot;version&quot;</span>\n]</code></pre>\n\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;.log.pages[0] | keys&#x27;</span> twitter.com.har\n\n[\n  <span class=\"hljs-string\">&quot;id&quot;</span>,\n  <span class=\"hljs-string\">&quot;pageTimings&quot;</span>,\n  <span class=\"hljs-string\">&quot;startedDateTime&quot;</span>,\n  <span class=\"hljs-string\">&quot;title&quot;</span>\n]</code></pre>\n\n<p>We will not go into an exploration of the complete format. Besides interactive exploration through jq it may also be useful to consult the <a href=\"http://www.softwareishard.com/blog/har-12-spec/\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">HAR specification</a> on how this file is structured.</p>\n<h2 id=\"Enumerating-accessed-resources\"><a href=\"#Enumerating-accessed-resources\" class=\"headerlink\" title=\"Enumerating accessed resources\"></a>Enumerating accessed resources</h2><p>As part of our exploration we&#39;d usually want to narrow down our selection by the HTTP resources which were accessed.</p>\n<p>We can find all the urls that were accessed as a part of this browsing session:</p>\n<pre><code class=\"hljs sh\">jq <span class=\"hljs-string\">&#x27;.log.entries[] | .request.url&#x27;</span> twitter.com.har\n\n<span class=\"hljs-string\">&quot;https://twitter.com/home&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/polyfills.18a65025.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/vendors~main.d0d6d775.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/i18n/en.96bbaf75.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/main.a3119725.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/ondemand.Dropdown.fa0fef85.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/sharedCore.c5e0a615.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/ondemand.Dropdown.fa0fef85.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/favicons/twitter.ico&quot;</span>\n...</code></pre>\n\n<p>We would often be interested in a subset of these resources. We can filter by HTTP method:</p>\n<pre><code class=\"hljs sh\">jq <span class=\"hljs-string\">&#x27;.log.entries[] | select(.request.method == &quot;GET&quot;) | .request.url&#x27;</span> twitter.com.har</code></pre>\n\n<p>(Note use of select function to select by a predicate)</p>\n<p>Or by extension:</p>\n<pre><code class=\"hljs sh\">jq <span class=\"hljs-string\">&#x27;.log.entries[] | select(.request.url | test(&quot;.js$&quot;)) | .request.url&#x27;</span> twitter.com.har</code></pre>\n\n<p>(Note use of <code>test</code> to create a predicate based on regular expression)</p>\n<p>A better alternative (for well behaved services anyways) for filtering with type of content is to filter by mime type:</p>\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;.log.entries[] | select(.response.content.mimeType == &quot;text/html&quot;) | .request.url&#x27;</span> twitter.com.har\n\n<span class=\"hljs-string\">&quot;https://twitter.com/home&quot;</span>\n\n$ jq <span class=\"hljs-string\">&#x27;.log.entries[] | select(.response.content.mimeType == &quot;application/javascript&quot;) | .request.url&#x27;</span> twitter.com.har\n\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/polyfills.18a65025.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/vendors~main.d0d6d775.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/i18n/en.96bbaf75.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/main.a3119725.js&quot;</span>\n<span class=\"hljs-string\">&quot;https://abs.twimg.com/responsive-web/client-web/ondemand.Dropdown.fa0fef85.js&quot;</span>\n..</code></pre>\n\n<p>If we want to get the first item, we can collect all the results into an array and apply the first filter on it</p>\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;[.log.entries[] | select(.request.url | test(&quot;home\\\\.json&quot;))] | first&#x27;</span> twitter.com.har  | less</code></pre>\n\n<p>(Note the use of <code>[...]</code> to collect the resultset into an array so that we can apply functions (in this case <code>first</code>) that operate on arrays).</p>\n<p>This gives us the first request to home.json</p>\n<h2 id=\"Exploring-response\"><a href=\"#Exploring-response\" class=\"headerlink\" title=\"Exploring response\"></a>Exploring response</h2><p>jq is useful primarily for json.</p>\n<p>So for services returning json we can just use jq to further explore the server response as well.</p>\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;[.log.entries[] | select(.request.url | test(&quot;home\\\\.json&quot;))] | first | .response.content.text&#x27;</span> twitter.com.har</code></pre>\n\n<p>However this gives us a string containing json, so before can apply further filters we&#39;ll have to unwrap this content.</p>\n<pre><code class=\"hljs sh\">$ jq <span class=\"hljs-string\">&#x27;[.log.entries[] | select(.request.url | test(&quot;home\\\\.json&quot;))] | first | .response.content.text | fromjson | .&#x27;</span> twitter.com.har</code></pre>\n\n<p>(Note the use of <code>fromjson</code> to extract the JSON content embedded in the string).</p>\n<p>But for other formats we can forward the result of jq to something else that deal with that format.</p>\n<p>So for instance, if you have <a href=\"https://github.com/sharkdp/bat\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">bat</a> installed, we can do something like this to get syntax highlighted HTML content.</p>\n<pre><code class=\"hljs sh\">$ jq -r <span class=\"hljs-string\">&#x27;[.log.entries[] | select(.response.content.mimeType == &quot;text/html&quot;) ] | first | .response.content.text | @base64d&#x27;</span> twitter.com.har  | bat</code></pre>\n\n<p>Remember our mention above about jq being composable ? jq fits in well with unix philosophy - doing one thing well and making it easy to use with other tools.</p>\n<p>Before we go further, a couple of things to note here:</p>\n<p>In case of twitter, the response from the server is base64 encoded. So we had to use <code>@base64d</code> to decode it. Also we had to pass the <code>-r</code> flag to jq to remove the quotes around the output so that the output is proper HTML.</p>\n<p>We can&#39;t however use the <code>@base64d</code> when the input is not utf8. But fortunately we have a base64 cli utility available for OS X (pre-installed) and most major linux variants which works well with arbitrary content including binary data.</p>\n<p>So we can save some images fetched during the HTTP session to a image files which can then be viewed through any image viewer:</p>\n<pre><code class=\"hljs sh\">$ jq -r <span class=\"hljs-string\">&#x27;[ .log.entries[] | select(.response.content.mimeType == &quot;image/png&quot;) ] | first | .response.content.text&#x27;</span> twitter.com.har | base64 --decode &gt; file.png</code></pre>\n\n<p>You can now, for instance, use something like <a href=\"https://github.com/dmtrKovalenko/odiff\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">odiff</a> to compare images from multiple HAR archives and see if they have changed.</p>\n<p>Also, if you are using <a href=\"https://iterm2.com/\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">iterm2</a> and have <a href=\"https://iterm2.com/documentation-images.html\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">imgcat</a> installed, we can display the images right in the terminal:</p>\n<pre><code class=\"hljs sh\">$ jq -r <span class=\"hljs-string\">&#x27;[ .log.entries[] | select(.response.content.mimeType == &quot;image/png&quot;) ] | first | .response.content.text&#x27;</span> twitter.com.har | base64 --decode | imgcat</code></pre>\n\n\n<p><img src=\"/images/Uw4uhn_mK.png\" alt=\"image.png\" loading=\"lazy\"></p>\n<h2 id=\"Summarizing-stats\"><a href=\"#Summarizing-stats\" class=\"headerlink\" title=\"Summarizing stats\"></a>Summarizing stats</h2><p>If you are analyzing HAR files you probably care about size of the paylodas.</p>\n<p>Let&#39;s sort the responses by download size and take the top 10:</p>\n<pre><code class=\"hljs sh\">jq -r <span class=\"hljs-string\">&#x27;[.log.entries[]] | sort_by(.response.content.size) | reverse | .[0:10] | map([.request.url, .response.content.size])&#x27;</span> twitter.com.har</code></pre>\n\n<p>Couple of things here:</p>\n<ul>\n<li>Note the use of <code>sort_by</code> operator to sort results</li>\n<li>This function operates on arrays, so we constructed one using <code>[.log.entries[]]</code> similar to before.</li>\n<li>We use <code>reverse</code> to reverse the array and <code>.[0:10]</code> slice operator to take a slice of first 10 results</li>\n<li>Finally we are not interested in the whole data - just the size and url so we use <code>map</code> to map over the results and extract exactly what we needed.</li>\n</ul>\n<p>We can also generate a CSV from this resultset which you can then preview in your favorite spreadsheet software:</p>\n<pre><code class=\"hljs sh\">jq -r <span class=\"hljs-string\">&#x27;[.log.entries[]] | sort_by(.response.content.size) | reverse | .[0:10] | map([.request.url, .response.content.size]) | [&quot;url&quot;, &quot;size&quot;],  .[] | @csv&#x27;</span> twitter.com.har</code></pre>\n\n<p>Personally I prefer using <a href=\"https://github.com/johnkerl/miller\" target=\"_blank\" rel=\"noopener external nofollow noreferrer\">miller</a> for exploring tabular data but that is a topic for another post.</p>\n<p>One thing to note here is that in all of the above examples, we didn&#39;t (need to) use any variables, loops etc. We just applied functional transformations over a stream of json - resulting in succinct and easy to grok code.</p>\n<p>This is one of the things that makes jq such an elegant choice for this kind of work. We do have functions, variables, foreach etc. but for most simple use cases like the ones above we don&#39;t need them.</p>\n<p>This brings us to end of our post. Hope this serves as a quick reference for common one-liners when dealing with jq &amp; har files and points you to the right direction for use-cases not covered above.</p>\n",
            "tags": [
                "HAR",
                "Jq"
            ]
        }
    ]
}